{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to predictive analysis: the sinking of Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/titanic-gettingStarted\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the usual packages...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/backends/backend_gtk3agg.py:18: UserWarning: The Gtk3Agg backend is known to not work on Python 3.x with pycairo. Try installing cairocffi.\n",
      "  \"The Gtk3Agg backend is known to not work on Python 3.x with pycairo. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import statsmodels.api as sm\n",
    "#from statsmodels import api as smf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "#import seaborn as sns\n",
    "import seaborn.apionly as sns\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = \"../datasets/\"\n",
    "outputs = \"../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(datapath,'Kaggle/kaggle_titanic_train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(datapath,'Kaggle/kaggle_titanic_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#df_train.columns\n",
    "#df_train.dtypes\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
       "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
       "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1, 2, 3]\n",
      "[0, 1, 2, 3, 4, 5, 8]\n",
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df_train.Survived.unique()))\n",
    "print(sorted(df_train.Pclass.unique()))\n",
    "print(sorted(df_train.SibSp.unique()))\n",
    "print(df_train.Embarked.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">female</th>\n",
       "      <th>count</th>\n",
       "      <td>261.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.915709</td>\n",
       "      <td>44.479818</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>431.028662</td>\n",
       "      <td>2.159236</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.110146</td>\n",
       "      <td>57.997698</td>\n",
       "      <td>1.022846</td>\n",
       "      <td>256.846324</td>\n",
       "      <td>0.857290</td>\n",
       "      <td>1.156520</td>\n",
       "      <td>0.438211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.071875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>414.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>641.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">male</th>\n",
       "      <th>count</th>\n",
       "      <td>453.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.726645</td>\n",
       "      <td>25.523893</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>454.147314</td>\n",
       "      <td>2.389948</td>\n",
       "      <td>0.429809</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.678201</td>\n",
       "      <td>43.138263</td>\n",
       "      <td>0.612294</td>\n",
       "      <td>257.486139</td>\n",
       "      <td>0.813580</td>\n",
       "      <td>1.061811</td>\n",
       "      <td>0.391775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Age        Fare       Parch  PassengerId      Pclass  \\\n",
       "Sex                                                                         \n",
       "female count  261.000000  314.000000  314.000000   314.000000  314.000000   \n",
       "       mean    27.915709   44.479818    0.649682   431.028662    2.159236   \n",
       "       std     14.110146   57.997698    1.022846   256.846324    0.857290   \n",
       "       min      0.750000    6.750000    0.000000     2.000000    1.000000   \n",
       "       25%           NaN   12.071875    0.000000   231.750000    1.000000   \n",
       "       50%           NaN   23.000000    0.000000   414.500000    2.000000   \n",
       "       75%           NaN   55.000000    1.000000   641.250000    3.000000   \n",
       "       max     63.000000  512.329200    6.000000   889.000000    3.000000   \n",
       "male   count  453.000000  577.000000  577.000000   577.000000  577.000000   \n",
       "       mean    30.726645   25.523893    0.235702   454.147314    2.389948   \n",
       "       std     14.678201   43.138263    0.612294   257.486139    0.813580   \n",
       "       min      0.420000    0.000000    0.000000     1.000000    1.000000   \n",
       "       25%           NaN    7.895800    0.000000   222.000000    2.000000   \n",
       "       50%           NaN   10.500000    0.000000   464.000000    3.000000   \n",
       "       75%           NaN   26.550000    0.000000   680.000000    3.000000   \n",
       "       max     80.000000  512.329200    5.000000   891.000000    3.000000   \n",
       "\n",
       "                   SibSp    Survived  \n",
       "Sex                                   \n",
       "female count  314.000000  314.000000  \n",
       "       mean     0.694268    0.742038  \n",
       "       std      1.156520    0.438211  \n",
       "       min      0.000000    0.000000  \n",
       "       25%      0.000000    0.000000  \n",
       "       50%      0.000000    1.000000  \n",
       "       75%      1.000000    1.000000  \n",
       "       max      8.000000    1.000000  \n",
       "male   count  577.000000  577.000000  \n",
       "       mean     0.429809    0.188908  \n",
       "       std      1.061811    0.391775  \n",
       "       min      0.000000    0.000000  \n",
       "       25%      0.000000    0.000000  \n",
       "       50%      0.000000    0.000000  \n",
       "       75%      0.000000    0.000000  \n",
       "       max      8.000000    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_sex = df_train.groupby('Sex')\n",
    "df_by_sex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['Gender'] = df_train['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "df_train['Embarked'] = df_train['Embarked'].map( {np.nan:0,'C':1, 'Q':2,'S':3} ).astype(int)\n",
    "df_test['Gender'] = df_test['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "df_test['Embarked'] = df_test['Embarked'].map( {np.nan:0,'C':1, 'Q':2,'S':3} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>186.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.233441</td>\n",
       "      <td>2.175926</td>\n",
       "      <td>84.154687</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>461.597222</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.996073</td>\n",
       "      <td>78.380373</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.693997</td>\n",
       "      <td>246.737616</td>\n",
       "      <td>0.611898</td>\n",
       "      <td>0.484026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.923950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>60.287500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>670.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2</th>\n",
       "      <th>count</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.877630</td>\n",
       "      <td>2.798913</td>\n",
       "      <td>20.662183</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>445.956522</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.589340</td>\n",
       "      <td>13.417399</td>\n",
       "      <td>0.493724</td>\n",
       "      <td>0.690963</td>\n",
       "      <td>250.852161</td>\n",
       "      <td>0.601633</td>\n",
       "      <td>0.500623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>435.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
       "      <th>count</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.140620</td>\n",
       "      <td>2.584521</td>\n",
       "      <td>13.675550</td>\n",
       "      <td>0.706721</td>\n",
       "      <td>0.393075</td>\n",
       "      <td>439.154786</td>\n",
       "      <td>0.615071</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.716058</td>\n",
       "      <td>11.778142</td>\n",
       "      <td>0.455730</td>\n",
       "      <td>0.888861</td>\n",
       "      <td>264.441453</td>\n",
       "      <td>1.374883</td>\n",
       "      <td>0.428949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>666.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>69.550000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Age    Embarked        Fare      Gender       Parch  \\\n",
       "Pclass                                                                     \n",
       "1      count  186.000000  216.000000  216.000000  216.000000  216.000000   \n",
       "       mean    38.233441    2.175926   84.154687    0.564815    0.356481   \n",
       "       std     14.802856    0.996073   78.380373    0.496933    0.693997   \n",
       "       min      0.920000    0.000000    0.000000    0.000000    0.000000   \n",
       "       25%           NaN    1.000000   30.923950    0.000000    0.000000   \n",
       "       50%           NaN    3.000000   60.287500    1.000000    0.000000   \n",
       "       75%           NaN    3.000000   93.500000    1.000000    0.000000   \n",
       "       max     80.000000    3.000000  512.329200    1.000000    4.000000   \n",
       "2      count  173.000000  184.000000  184.000000  184.000000  184.000000   \n",
       "       mean    29.877630    2.798913   20.662183    0.586957    0.380435   \n",
       "       std     14.001077    0.589340   13.417399    0.493724    0.690963   \n",
       "       min      0.670000    1.000000    0.000000    0.000000    0.000000   \n",
       "       25%           NaN    3.000000   13.000000    0.000000    0.000000   \n",
       "       50%           NaN    3.000000   14.250000    1.000000    0.000000   \n",
       "       75%           NaN    3.000000   26.000000    1.000000    1.000000   \n",
       "       max     70.000000    3.000000   73.500000    1.000000    3.000000   \n",
       "3      count  355.000000  491.000000  491.000000  491.000000  491.000000   \n",
       "       mean    25.140620    2.584521   13.675550    0.706721    0.393075   \n",
       "       std     12.495398    0.716058   11.778142    0.455730    0.888861   \n",
       "       min      0.420000    1.000000    0.000000    0.000000    0.000000   \n",
       "       25%           NaN    2.000000    7.750000    0.000000    0.000000   \n",
       "       50%           NaN    3.000000    8.050000    1.000000    0.000000   \n",
       "       75%           NaN    3.000000   15.500000    1.000000    0.000000   \n",
       "       max     74.000000    3.000000   69.550000    1.000000    6.000000   \n",
       "\n",
       "              PassengerId       SibSp    Survived  \n",
       "Pclass                                             \n",
       "1      count   216.000000  216.000000  216.000000  \n",
       "       mean    461.597222    0.416667    0.629630  \n",
       "       std     246.737616    0.611898    0.484026  \n",
       "       min       2.000000    0.000000    0.000000  \n",
       "       25%     270.750000    0.000000    0.000000  \n",
       "       50%     472.000000    0.000000    1.000000  \n",
       "       75%     670.500000    1.000000    1.000000  \n",
       "       max     890.000000    3.000000    1.000000  \n",
       "2      count   184.000000  184.000000  184.000000  \n",
       "       mean    445.956522    0.402174    0.472826  \n",
       "       std     250.852161    0.601633    0.500623  \n",
       "       min      10.000000    0.000000    0.000000  \n",
       "       25%     234.500000    0.000000    0.000000  \n",
       "       50%     435.500000    0.000000    0.000000  \n",
       "       75%     668.000000    1.000000    1.000000  \n",
       "       max     887.000000    3.000000    1.000000  \n",
       "3      count   491.000000  491.000000  491.000000  \n",
       "       mean    439.154786    0.615071    0.242363  \n",
       "       std     264.441453    1.374883    0.428949  \n",
       "       min       1.000000    0.000000    0.000000  \n",
       "       25%     200.000000    0.000000    0.000000  \n",
       "       50%     432.000000    0.000000    0.000000  \n",
       "       75%     666.500000    1.000000    0.000000  \n",
       "       max     891.000000    8.000000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_class = df_train.groupby('Pclass')\n",
    "df_by_class.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.590909</td>\n",
       "      <td>66.022727</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.854071</td>\n",
       "      <td>5.024884</td>\n",
       "      <td>0.428932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pclass        Age   Survived\n",
       "count  22.000000  22.000000  22.000000\n",
       "mean    1.590909  66.022727   0.227273\n",
       "std     0.854071   5.024884   0.428932\n",
       "min     1.000000  61.000000   0.000000\n",
       "25%     1.000000  62.000000   0.000000\n",
       "50%     1.000000  64.500000   0.000000\n",
       "75%     2.000000  70.000000   0.000000\n",
       "max     3.000000  80.000000   1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['Age'] > 60][['Sex', 'Pclass', 'Age', 'Survived']].describe()\n",
    "#df_train[df_train['Age'].isnull()][['Sex', 'Pclass', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homens\n",
      "1 122\n",
      "2 108\n",
      "3 347\n",
      "\n",
      "Mulheres\n",
      "1 94\n",
      "2 76\n",
      "3 144\n"
     ]
    }
   ],
   "source": [
    "print('Homens')\n",
    "for i in range(1,4):\n",
    "    print(i, len(df_train[ (df_train['Sex'] == 'male') & (df_train['Pclass'] == i) ]))\n",
    "print()\n",
    "print('Mulheres')\n",
    "for i in range(1,4):\n",
    "    print(i, len(df_train[ (df_train['Sex'] == 'female') & (df_train['Pclass'] == i) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbdbc52b9b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdbc52b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_train['Age'].hist()\n",
    "df_train['Age'].dropna().hist(bins=16, range=(0,80), alpha = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolvendo a questo dos valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['AgeFill'] = df_train['Age']\n",
    "df_test['AgeFill'] = df_test['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Pclass  Age  AgeFill\n",
       "5        1       3  NaN      NaN\n",
       "17       1       2  NaN      NaN\n",
       "19       0       3  NaN      NaN\n",
       "26       1       3  NaN      NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['Age'].isnull()][['Gender','Pclass','Age','AgeFill']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train[df_train['Age'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35. ,  28. ,  21.5],\n",
       "       [ 40. ,  30. ,  25. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_ages = np.zeros((2,3))\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = df_train[(df_train['Gender'] == i) & (df_train['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "median_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        df_train.loc[(df_train.Age.isnull()) & (df_train.Gender == i) & (df_train.Pclass == j+1),'AgeFill'] = median_ages[i,j]\n",
    "        df_test.loc[(df_test.Age.isnull()) & (df_test.Gender == i) & (df_test.Pclass == j+1),'AgeFill'] = median_ages[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null int64\n",
      "Gender         891 non-null int64\n",
      "AgeFill        891 non-null float64\n",
      "dtypes: float64(3), int64(7), object(4)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name      object\n",
       "Sex       object\n",
       "Ticket    object\n",
       "Cabin     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes[df_train.dtypes.map(lambda x: x=='object')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  SibSp  Parch     Fare  Gender  AgeFill  \\\n",
       "0            1         0       3      1      0   7.2500       1     22.0   \n",
       "1            2         1       1      1      0  71.2833       0     38.0   \n",
       "2            3         1       3      0      0   7.9250       0     26.0   \n",
       "3            4         1       1      1      0  53.1000       0     35.0   \n",
       "4            5         0       3      0      0   8.0500       1     35.0   \n",
       "\n",
       "   FamilySize  Age*Class  \n",
       "0           1       66.0  \n",
       "1           1       38.0  \n",
       "2           0       78.0  \n",
       "3           1       35.0  \n",
       "4           0      105.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch']\n",
    "df_train['Age*Class'] = df_train.AgeFill * df_train.Pclass\n",
    "df_train2 = df_train.drop(['Age','Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "df_train2 = df_train2.dropna()\n",
    "df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1. ,    0. ,    3. , ...,   22. ,    1. ,   66. ],\n",
       "       [   2. ,    1. ,    1. , ...,   38. ,    1. ,   38. ],\n",
       "       [   3. ,    1. ,    3. , ...,   26. ,    0. ,   78. ],\n",
       "       ..., \n",
       "       [ 889. ,    0. ,    3. , ...,   21.5,    3. ,   64.5],\n",
       "       [ 890. ,    1. ,    1. , ...,   26. ,    0. ,   26. ],\n",
       "       [ 891. ,    0. ,    3. , ...,   32. ,    0. ,   96. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df_train2.values\n",
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch     Fare  Gender  AgeFill  FamilySize  \\\n",
       "0          892       3      0      0   7.8292       1     34.5           0   \n",
       "1          893       3      1      0   7.0000       0     47.0           1   \n",
       "2          894       2      0      0   9.6875       1     62.0           0   \n",
       "3          895       3      0      0   8.6625       1     27.0           0   \n",
       "4          896       3      1      1  12.2875       0     22.0           2   \n",
       "\n",
       "   Age*Class  \n",
       "0      103.5  \n",
       "1      141.0  \n",
       "2      124.0  \n",
       "3       81.0  \n",
       "4       66.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch']\n",
    "df_test['Age*Class'] = df_test.AgeFill * df_test.Pclass\n",
    "df_test2 = df_test.drop(['Age','Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "df_test2 = df_test2.dropna()\n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8.92000000e+02,   3.00000000e+00,   0.00000000e+00, ...,\n",
       "          3.45000000e+01,   0.00000000e+00,   1.03500000e+02],\n",
       "       [  8.93000000e+02,   3.00000000e+00,   1.00000000e+00, ...,\n",
       "          4.70000000e+01,   1.00000000e+00,   1.41000000e+02],\n",
       "       [  8.94000000e+02,   2.00000000e+00,   0.00000000e+00, ...,\n",
       "          6.20000000e+01,   0.00000000e+00,   1.24000000e+02],\n",
       "       ..., \n",
       "       [  1.30700000e+03,   3.00000000e+00,   0.00000000e+00, ...,\n",
       "          3.85000000e+01,   0.00000000e+00,   1.15500000e+02],\n",
       "       [  1.30800000e+03,   3.00000000e+00,   0.00000000e+00, ...,\n",
       "          2.50000000e+01,   0.00000000e+00,   7.50000000e+01],\n",
       "       [  1.30900000e+03,   3.00000000e+00,   1.00000000e+00, ...,\n",
       "          2.50000000e+01,   2.00000000e+00,   7.50000000e+01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = df_test2.values\n",
    "print(test_data.shape)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  \n",
    "Adjusting features scales:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data[0::,2::])\n",
    "y_train = train_data[0::,1]\n",
    "X_test = scaler.fit_transform(test_data[0::,1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82737724,  0.43279337, -0.47367361, -0.50244517,  0.73769513,\n",
       "       -0.53489116,  0.05915988,  0.10799818])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stats.stackexchange.com/questions/95797/how-to-split-the-dataset-for-cross-validation-learning-curve-and-final-evaluat  \n",
    "http://scikit-learn.org/stable/modules/cross_validation.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating cross-validation with subsets (60% train / 40% test):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_traincv, X_testcv, y_traincv, y_testcv = cross_validation.train_test_split(X_train, \n",
    "                                                                             y_train, \n",
    "                                                                             test_size=0.4, \n",
    "                                                                             random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating another train/test set using k-fold or other cross-validation method:  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html  \n",
    "http://www.analyticsvidhya.com/blog/2015/05/k-fold-cross-validation-simple/  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html  \n",
    "http://stackoverflow.com/questions/25375203/identical-learning-curves-on-subsequent-runs-using-shufflesplit  \n",
    "http://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.KFold(len(X_train), n_folds=10)\n",
    "#cv = cross_validation.ShuffleSplit(X_train.shape[0], n_iter=10, test_size=0.2, random_state=0)\n",
    "\n",
    "def mean_scores_cv(clf, cv, X, y):\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, \n",
    "                                              scoring=None, \n",
    "                                              cv=cv, \n",
    "                                              n_jobs=1,\n",
    "                                              verbose=0,\n",
    "                                              fit_params=None,\n",
    "                                              pre_dispatch='2*n_jobs')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example on how to choose the best parameters using GridSearchCV\n",
    "#http://scikit-learn.org/0.11/tutorial/statistical_inference/model_selection.html\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821548821549\n",
      "poly\n",
      "1.57777777778\n",
      "2\n",
      "0.278255940221\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "estimator = svm.SVC()\n",
    "kernels = ['linear', 'poly']\n",
    "Cs = np.linspace(0.1,2,10)\n",
    "degrees = [2,3,4]\n",
    "gammas = np.logspace(-5, 0, 10)\n",
    "param_grid=dict(kernel=kernels, C=Cs, gamma=gammas, degree=degrees)\n",
    "\n",
    "clf1 = GridSearchCV(estimator=estimator,\n",
    "                    cv=cv,\n",
    "                    param_grid=param_grid, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "with open(os.path.join(outputs,'best_parameters_svm.pickle'), 'wb') as f:\n",
    "    pickle.dump(clf1,f)\n",
    "\n",
    "with open(os.path.join(outputs,'best_parameters_svm.pickle'), 'rb') as f:\n",
    "    clf1 = pickle.load(f)\n",
    "\n",
    "print(clf1.best_score_)\n",
    "print(clf1.best_estimator_.kernel)\n",
    "print(clf1.best_estimator_.C)\n",
    "print(clf1.best_estimator_.degree)\n",
    "print(clf1.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing some classifiers:  \n",
    "Note that only the first classifier (svm) had its parameters optimized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803921568627\n",
      "0.821573033708\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "clf1b = svm.SVC(kernel=clf1.best_estimator_.kernel,\n",
    "               C=clf1.best_estimator_.C,\n",
    "               degree=clf1.best_estimator_.degree, \n",
    "               gamma=clf1.best_estimator_.gamma, \n",
    "               coef0=0.0, \n",
    "               shrinking=True, \n",
    "               probability=False, \n",
    "               tol=0.001, \n",
    "               cache_size=200, \n",
    "               class_weight=None, \n",
    "               verbose=False, \n",
    "               max_iter=-1, \n",
    "               random_state=0).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval1_tts = clf1b.score(X_testcv, y_testcv)\n",
    "print(eval1_tts)\n",
    "\n",
    "eval1_cv = mean_scores_cv(clf1b, cv, X_train, y_train)\n",
    "print(eval1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first classifier, we'll also display the learning curve  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.learning_curve.learning_curve.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.learning_curve.learning_curve.html\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, \n",
    "                        title, \n",
    "                        X, \n",
    "                        y, \n",
    "                        ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=-1, \n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, \n",
    "                                                            X, y, cv=cv, \n",
    "                                                            n_jobs=n_jobs, \n",
    "                                                            train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA70AAAH6CAYAAADLHytRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f117f563128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = 'Learning Curves (SVM, kernel:{1}{0} , $\\gamma={2:.6f}$)'.format(clf1.best_estimator_.degree,\n",
    "                                                                         clf1.best_estimator_.kernel,\n",
    "                                                                         clf1.best_estimator_.gamma)\n",
    "graph = plot_learning_curve(clf1b, title, X_train, y_train, cv=cv)\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos testar outros estimadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803921568627\n",
      "0.810399500624\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/ensemble.html\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#http://blog.yhathq.com/posts/random-forests-in-python.html\n",
    "#http://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf2 = RandomForestClassifier(n_estimators=300, \n",
    "                              criterion='gini', \n",
    "                              max_depth=None, \n",
    "                              min_samples_split=2, \n",
    "                              min_samples_leaf=1, \n",
    "                              min_weight_fraction_leaf=0.0, \n",
    "                              max_features='auto', \n",
    "                              max_leaf_nodes=None, \n",
    "                              bootstrap=True, \n",
    "                              oob_score=False, \n",
    "                              n_jobs=-1, \n",
    "                              random_state=0, \n",
    "                              verbose=0, \n",
    "                              warm_start=False, \n",
    "                              class_weight=None).fit(X_traincv, y_traincv)\n",
    "\n",
    "\n",
    "\n",
    "eval2_tts = clf2.score(X_testcv, y_testcv)\n",
    "print(eval2_tts)\n",
    "\n",
    "eval2_cv = mean_scores_cv(clf2, cv, X_train, y_train)\n",
    "print(eval2_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775910364146\n",
      "0.786816479401\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf3 = DecisionTreeClassifier(criterion='gini', \n",
    "                              splitter='best', \n",
    "                              max_depth=None, \n",
    "                              min_samples_split=1, \n",
    "                              min_samples_leaf=1, \n",
    "                              min_weight_fraction_leaf=0.0, \n",
    "                              max_features=None, \n",
    "                              random_state=0, \n",
    "                              max_leaf_nodes=None, \n",
    "                              class_weight=None, \n",
    "                              presort=False).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval3_tts = clf3.score(X_testcv, y_testcv)\n",
    "print(eval3_tts)\n",
    "\n",
    "eval3_cv = mean_scores_cv(clf3, cv, X_train, y_train)\n",
    "print(eval3_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795518207283\n",
      "0.802534332085\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf4 = ExtraTreesClassifier(n_estimators=300,\n",
    "                            max_depth=None,\n",
    "                            min_samples_split=1,\n",
    "                            random_state=0).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval4_tts = clf4.score(X_testcv, y_testcv)\n",
    "print(eval4_tts)\n",
    "\n",
    "eval4_cv = mean_scores_cv(clf4, cv, X_train, y_train)\n",
    "print(eval4_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820728291317\n",
      "0.821573033708\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf5 = AdaBoostClassifier(base_estimator=None,\n",
    "                          n_estimators=200,\n",
    "                          learning_rate=0.1,\n",
    "                          algorithm='SAMME.R',\n",
    "                          random_state=0).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval5_tts = clf5.score(X_testcv, y_testcv)\n",
    "print(eval5_tts)\n",
    "\n",
    "eval5_cv = mean_scores_cv(clf5, cv, X_train, y_train)\n",
    "print(eval5_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803921568627\n",
      "0.839525593009\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf6 = GradientBoostingClassifier(loss='deviance',\n",
    "                                  learning_rate=0.1,\n",
    "                                  n_estimators=200,\n",
    "                                  subsample=1.0, \n",
    "                                  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, \n",
    "                                  max_depth=3, \n",
    "                                  init=None, \n",
    "                                  random_state=0, \n",
    "                                  max_features=None, \n",
    "                                  verbose=0, \n",
    "                                  max_leaf_nodes=None, \n",
    "                                  warm_start=False, \n",
    "                                  presort='auto').fit(X_traincv, y_traincv)\n",
    "\n",
    "eval6_tts = clf6.score(X_testcv, y_testcv)\n",
    "print(eval6_tts)\n",
    "\n",
    "eval6_cv = mean_scores_cv(clf6, cv, X_train, y_train)\n",
    "rint(eval6_cv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#https://github.com/dmlc/xgboost/tree/master/python-package  \n",
    "#https://xgboost.readthedocs.io/en/latest/build.html#building-on-ubuntu-debian\n",
    "#http://xgboost.readthedocs.io/en/latest/build.html#python-package-installation  \n",
    "#http://xgboost.readthedocs.io/en/latest/parameter.html  \n",
    "#https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/  \n",
    "#https://www.kaggle.com/cbrogan/titanic/xgboost-example-python/run/1620  \n",
    "\n",
    "import xgboost\n",
    "\n",
    "xgb2 = xgboost.sklearn.XGBClassifier(learning_rate =0.1,\n",
    "                                     n_estimators=1000, \n",
    "                                     max_depth=5,\n",
    "                                     min_child_weight=1, \n",
    "                                     gamma=0,\n",
    "                                     subsample=0.8, \n",
    "                                     colsample_bytree=0.8, \n",
    "                                     objective= 'binary:logitraw',\n",
    "                                     eval_metric='rmse',\n",
    "                                     nthread=4,\n",
    "                                     scale_pos_weight=1, \n",
    "                                     seed=0)\n",
    "\n",
    "xgb2 = xgb2.fit(X_traincv, y_traincv)\n",
    "\n",
    "#evalxgb1_tts = xgb2.score(X_testcv, y_testcv)\n",
    "#print(evalxgb1_tts)\n",
    "\n",
    "#evalxgb1_cv = mean_scores_cv(xgb2, cv, X_train, y_train)\n",
    "#print(evalxgb1_cv)\n",
    "#xgb2.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781512605042\n",
      "0.791285892634\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf7 = SGDClassifier(loss='hinge',\n",
    "                     penalty='l2', \n",
    "                     alpha=0.0001,\n",
    "                     l1_ratio=0.15, \n",
    "                     fit_intercept=True,\n",
    "                     n_iter=200, \n",
    "                     shuffle=True,\n",
    "                     verbose=0,\n",
    "                     epsilon=0.1,\n",
    "                     n_jobs=-1,\n",
    "                     random_state=0,\n",
    "                     learning_rate='optimal',\n",
    "                     eta0=0.0, \n",
    "                     power_t=0.5,\n",
    "                     class_weight=None,\n",
    "                     warm_start=False, \n",
    "                     average=False).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval7_tts = clf7.score(X_testcv, y_testcv)\n",
    "print(eval7_tts)\n",
    "\n",
    "eval7_cv = mean_scores_cv(clf7, cv, X_train, y_train)\n",
    "print(eval7_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781512605042\n",
      "0.795730337079\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf8 = RidgeClassifier(alpha=1.0, \n",
    "                       fit_intercept=True, \n",
    "                       normalize=False, \n",
    "                       copy_X=True, \n",
    "                       max_iter=None, \n",
    "                       tol=0.001, \n",
    "                       class_weight=None, \n",
    "                       solver='auto', \n",
    "                       random_state=0).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval8_tts = clf8.score(X_testcv, y_testcv)\n",
    "print(eval8_tts)\n",
    "\n",
    "eval8_cv = mean_scores_cv(clf8, cv, X_train, y_train)\n",
    "\n",
    "print(eval8_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641456582633\n",
      "0.71606741573\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf9 = Perceptron(penalty=None,\n",
    "                  alpha=0.0001,\n",
    "                  fit_intercept=True,\n",
    "                  n_iter=5,\n",
    "                  shuffle=True,\n",
    "                  verbose=0,\n",
    "                  eta0=1.0,\n",
    "                  n_jobs=-1, \n",
    "                  random_state=0, \n",
    "                  class_weight=None, \n",
    "                  warm_start=False).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval9_tts = clf9.score(X_testcv, y_testcv)\n",
    "print(eval9_tts)\n",
    "\n",
    "eval9_cv = mean_scores_cv(clf9, cv, X_train, y_train)\n",
    "\n",
    "print(eval9_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775910364146\n",
      "0.753358302122\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "clf10 = PassiveAggressiveClassifier(C=1.0, \n",
    "                                    fit_intercept=True, \n",
    "                                    n_iter=300, \n",
    "                                    shuffle=True, \n",
    "                                    verbose=0, \n",
    "                                    loss='hinge', \n",
    "                                    n_jobs=-1, \n",
    "                                    random_state=0, \n",
    "                                    warm_start=False, \n",
    "                                    class_weight=None).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval10_tts = clf10.score(X_testcv, y_testcv)\n",
    "print(eval10_tts)\n",
    "\n",
    "eval10_cv = mean_scores_cv(clf10, cv, X_train, y_train)\n",
    "\n",
    "print(eval10_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806722689076\n",
      "0.799101123596\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf11 = LogisticRegression(penalty='l2',\n",
    "                           dual=False, \n",
    "                           tol=0.0001, \n",
    "                           C=1.0, \n",
    "                           fit_intercept=True, \n",
    "                           intercept_scaling=1, \n",
    "                           class_weight=None, \n",
    "                           random_state=0, \n",
    "                           solver='liblinear', \n",
    "                           max_iter=100, \n",
    "                           multi_class='ovr', \n",
    "                           verbose=0, \n",
    "                           warm_start=False, \n",
    "                           n_jobs=-1).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval11_tts = clf11.score(X_testcv, y_testcv)\n",
    "print(eval11_tts)\n",
    "\n",
    "eval11_cv = mean_scores_cv(clf11, cv, X_train, y_train)\n",
    "\n",
    "print(eval11_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78431372549\n",
      "0.780062421973\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf12 = GaussianNB().fit(X_traincv, y_traincv)\n",
    "\n",
    "eval12_tts = clf12.score(X_testcv, y_testcv)\n",
    "print(eval12_tts)\n",
    "\n",
    "eval12_cv = mean_scores_cv(clf12, cv, X_train, y_train)\n",
    "\n",
    "print(eval12_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719887955182\n",
      "0.727365792759\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf13 = BernoulliNB(alpha=1.0, \n",
    "                    binarize=0.0, \n",
    "                    fit_prior=True, \n",
    "                    class_prior=None).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval13_tts = clf13.score(X_testcv, y_testcv)\n",
    "print(eval13_tts)\n",
    "\n",
    "eval13_cv = mean_scores_cv(clf13, cv, X_train, y_train)\n",
    "\n",
    "print(eval13_cv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf14 = MultinomialNB(alpha=1.0,\n",
    "                      fit_prior=True,\n",
    "                      class_prior=None).fit(X_traincv, y_traincv)\n",
    "\n",
    "eval14_tts = clf14.score(X_testcv, y_testcv)\n",
    "print(eval14_tts)\n",
    "\n",
    "eval14_cv = mean_scores_cv(clf14, cv, X_train, y_train)\n",
    "\n",
    "print(eval14_cv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nolearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6b6d4d6b1274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnolearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlasagne\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m clf15_layers = [('input', lasagne.layers.InputLayer),\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nolearn'"
     ]
    }
   ],
   "source": [
    "#pip install -r https://raw.githubusercontent.com/Lasagne/Lasagne/v0.1/requirements.txt \n",
    "#pip install https://github.com/dnouri/nolearn/archive/master.zip#egg=nolearn\n",
    "#sudo pip install --upgrade theano\n",
    "\n",
    "#http://stackoverflow.com/questions/30034492/does-nolearn-lasagne-support-python-3\n",
    "#https://gist.github.com/dnouri/fe855653e9757e1ce8c4\n",
    "#https://github.com/dnouri/nolearn/issues/62\n",
    "\n",
    "#https://github.com/dnouri/nolearn/blob/master/nolearn/lasagne/base.py\n",
    "#https://github.com/Lasagne/Lasagne/blob/master/lasagne/objectives.py\n",
    "\n",
    "#http://nbviewer.ipython.org/github/ottogroup/kaggle/blob/master/Otto_Group_Competition.ipynb\n",
    "#http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n",
    "\n",
    "import lasagne\n",
    "import nolearn\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "clf15_layers = [('input', lasagne.layers.InputLayer),\n",
    "                #('input', lasagne.layers.InputLayer(shape=(None, X.shape[1])))\n",
    "                #('dropout0', lasagne.layers.DropoutLayer),\n",
    "                ('dense0', lasagne.layers.DenseLayer),\n",
    "                ('dropout1', lasagne.layers.DropoutLayer),#\n",
    "                ('dense1', lasagne.layers.DenseLayer),\n",
    "                #('dropout2', lasagne.layers.DropoutLayer),#\n",
    "                ('output', lasagne.layers.DenseLayer)]\n",
    "\n",
    "#l = InputLayer(shape=(None, X.shape[1]))\n",
    "#l = DenseLayer(l, num_units=len(np.unique(y)), nonlinearity=softmax)\n",
    "#net = NeuralNet(l, update_learning_rate=0.01)\n",
    "\n",
    "clf15 = nolearn.lasagne.NeuralNet(layers=clf15_layers,\n",
    "                                  input_shape=(None, X_traincv.shape[1]), #num_features\n",
    "                                  #dropout0_p=0.5, #0.15                 \n",
    "                                  dense0_num_units=200,\n",
    "                                  dropout1_p=0.25,\n",
    "                                  dense1_num_units=200,\n",
    "                                  #dropout2_p=0.25,\n",
    "                                  output_num_units=len(np.unique(y_traincv)), #num_classes\n",
    "                                  output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                  #update=lasagne.updates.adagrad,\n",
    "                                  update=lasagne.updates.nesterov_momentum,\n",
    "                                  update_momentum=0.5, #0.9 #only used with nesterov_momentum\n",
    "                                  update_learning_rate=0.01,\n",
    "                                  train_split=nolearn.lasagne.TrainSplit(eval_size=0.2), #split\n",
    "                                  verbose=0,\n",
    "                                  max_epochs=150, #To tune,verify the behaviour of outputs\n",
    "                                 )\n",
    "\n",
    "clf15.fit(X_traincv.astype(np.float32), y_traincv.astype(np.int32))\n",
    "\n",
    "eval15_tts = clf15.score(X_testcv.astype(np.float32), y_testcv.astype(np.int32))\n",
    "print(eval15_tts)\n",
    "\n",
    "eval15_cv = mean_scores_cv(clf15, cv, X_train.astype(np.float32), y_train.astype(np.int32))\n",
    "print(eval15_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss = np.array([i[\"train_loss\"] for i in clf15.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in clf15.train_history_])\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.ylim(1e-1, 1e1)\n",
    "plt.ylim(0.3, 0.8)\n",
    "#plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://lasagne.readthedocs.org/en/latest/\n",
    "#http://lasagne.readthedocs.org/en/latest/user/tutorial.html\n",
    "#https://github.com/Lasagne\n",
    "#https://martin-thoma.com/lasagne-for-python-newbies/\n",
    "#http://deeplearning.net/tutorial/\n",
    "#http://deeplearning.net/software/theano/tutorial/\n",
    "#http://cs231n.github.io/\n",
    "#http://neuralnetworksanddeeplearning.com/\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "#import lasagne\n",
    "\n",
    "def build_mlp(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(534,8),\n",
    "                                     input_var=input_var)\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in,\n",
    "                                            p=0.2)\n",
    "    l_hid1 = lasagne.layers.DenseLayer(l_in_drop, \n",
    "                                       num_units=800,\n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1,\n",
    "                                              p=0.6)\n",
    "    l_hid2 = lasagne.layers.DenseLayer(l_hid1_drop,\n",
    "                                       num_units=800,\n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2,\n",
    "                                              p=0.6)\n",
    "    l_out = lasagne.layers.DenseLayer(l_hid2_drop,\n",
    "                                      num_units=10,\n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out\n",
    "\n",
    "def build_custom_mlp(input_var=None, depth=2, width=800, drop_input=.2, drop_hidden=.5):\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(534,8),\n",
    "                                        input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(network, \n",
    "                                            width, \n",
    "                                            nonlinearity=nonlin)\n",
    "    if drop_hidden:\n",
    "        network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 10, nonlinearity=softmax)\n",
    "    return network\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    network = lasagne.layers.InputLayer(shape=(534,8),\n",
    "                                        input_var=input_var)\n",
    "    network = lasagne.layers.Conv2DLayer(network,\n",
    "                                         num_filters=32,\n",
    "                                         filter_size=(5, 5),\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                         W=lasagne.init.GlorotUniform())\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    network = lasagne.layers.Conv2DLayer(network, \n",
    "                                         num_filters=32,\n",
    "                                         filter_size=(5, 5),\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=.5),\n",
    "                                        num_units=256,\n",
    "                                        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=.5),\n",
    "                                        num_units=10,\n",
    "                                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.matrix('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model\n",
    "network = build_mlp(input_var)\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss,\n",
    "                                            params,\n",
    "                                            learning_rate=0.01, \n",
    "                                            momentum=0.9)\n",
    "# Monitoring progress during training\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "# Compilation\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates, allow_input_downcast=True)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    start_time = time.time()\n",
    "    inputs, targets = X_traincv, y_traincv\n",
    "    train_err += train_fn(inputs, targets)\n",
    "    \n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    inputs, targets = X_testcv, y_testcv\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    val_err += err\n",
    "    val_acc += acc\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_err = 0\n",
    "test_acc = 0\n",
    "inputs, targets = X_testcv, y_testcv\n",
    "err, acc = val_fn(inputs, targets)\n",
    "test_err += err\n",
    "test_acc += acc\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic_results = {'SVM': eval1_cv,\n",
    "               'RandomForest': eval2_cv,\n",
    "               'DecisionTree': eval3_cv,\n",
    "               'ExtraTree': eval4_cv,\n",
    "               'AdaBoost': eval5_cv,\n",
    "               'GradBoost': eval6_cv,\n",
    "               'SGDC': eval7_cv,\n",
    "               'Ridge': eval8_cv,\n",
    "               'Perceptron': eval9_cv,\n",
    "               'PassAgre': eval10_cv,\n",
    "               'LogiReg': eval11_cv,\n",
    "               'GaussianNB': eval12_cv,\n",
    "               'BernouNB': eval13_cv,\n",
    "               'NoLearn_Lasagne': eval15_cv,\n",
    "               'Lasagne': test_acc,\n",
    "              }\n",
    "\n",
    "import operator\n",
    "tup_results = sorted(dic_results.items(), key=operator.itemgetter(1))\n",
    "\n",
    "N = len(dic_results)\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.40       # the width of the bars\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111)\n",
    "rects = ax.bar(ind, list(zip(*tup_results))[1], width,)\n",
    "for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x()+rect.get_width()/2., \n",
    "            1.005*height, \n",
    "            '{0:.4f}'.format(height), \n",
    "            ha='center', \n",
    "            va='bottom',)\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_ylim(ymin=0.65,ymax = 0.85)\n",
    "ax.set_title(\"Classificators' performance\")\n",
    "ax.set_xticks(ind + width/2.)\n",
    "ax.set_xticklabels(list(zip(*tup_results))[0], rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the best classifier and training with all training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "clf = GradientBoostingClassifier(loss='deviance',\n",
    "                                  learning_rate=0.1,\n",
    "                                  n_estimators=200,\n",
    "                                  subsample=1.0, \n",
    "                                  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, \n",
    "                                  max_depth=3, \n",
    "                                  init=None, \n",
    "                                  random_state=0, \n",
    "                                  max_features=None, \n",
    "                                  verbose=0, \n",
    "                                  max_leaf_nodes=None, \n",
    "                                  warm_start=False, \n",
    "                                  presort='auto').fit(X_train,y_train)\n",
    "# Take the same decision trees and run it on the test data\n",
    "\n",
    "output = clf.predict(X_test)\n",
    "print(output[10:20])\n",
    "\n",
    "output_prob = clf.predict_proba(X_test)\n",
    "print(output_prob[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnng correlation hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df_train2.Survived\n",
    "X = df_train2.Gender\n",
    "model = sm.Logit(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df_train2.Survived\n",
    "X = df_train2[['Gender','Pclass','AgeFill']]\n",
    "model = sm.Logit(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
